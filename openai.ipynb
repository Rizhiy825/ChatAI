{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caef2523",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key=\"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\"\n",
    ")\n",
    "\n",
    "response = client.responses.create(\n",
    "  model=\"gpt-5-nano\",\n",
    "  input=\"write a haiku about ai\",\n",
    "  store=True,\n",
    ")\n",
    "\n",
    "print(response.output_text);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a1983c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== File Search Result ===\n",
      "{\n",
      "  \"results\": [\n",
      "    {\n",
      "      \"id\": null,\n",
      "      \"score\": 0.8037339638661657,\n",
      "      \"filename\": \"Diagonal Panel Z.txt\",\n",
      "      \"metadata\": null\n",
      "    },\n",
      "    {\n",
      "      \"id\": null,\n",
      "      \"score\": 0.8003527077760549,\n",
      "      \"filename\": \"Diagonal Panel X.txt\",\n",
      "      \"metadata\": null\n",
      "    },\n",
      "    {\n",
      "      \"id\": null,\n",
      "      \"score\": 0.7924214874271837,\n",
      "      \"filename\": \"Diagonal Panel Y.txt\",\n",
      "      \"metadata\": null\n",
      "    },\n",
      "    {\n",
      "      \"id\": null,\n",
      "      \"score\": 0.7730704761680375,\n",
      "      \"filename\": \"Diagonal Separator Z.txt\",\n",
      "      \"metadata\": null\n",
      "    },\n",
      "    {\n",
      "      \"id\": null,\n",
      "      \"score\": 0.7653841774265965,\n",
      "      \"filename\": \"Diagonal Separator X.txt\",\n",
      "      \"metadata\": null\n",
      "    },\n",
      "    {\n",
      "      \"id\": null,\n",
      "      \"score\": 0.7625620291539081,\n",
      "      \"filename\": \"Diagonal Separator Y.txt\",\n",
      "      \"metadata\": null\n",
      "    },\n",
      "    {\n",
      "      \"id\": null,\n",
      "      \"score\": 0.5488680647492704,\n",
      "      \"filename\": \"Carcass Connector.txt\",\n",
      "      \"metadata\": null\n",
      "    },\n",
      "    {\n",
      "      \"id\": null,\n",
      "      \"score\": 0.5461228555439296,\n",
      "      \"filename\": \"Universal Panel.txt\",\n",
      "      \"metadata\": null\n",
      "    },\n",
      "    {\n",
      "      \"id\": null,\n",
      "      \"score\": 0.5191366141488389,\n",
      "      \"filename\": \"Connectors.txt\",\n",
      "      \"metadata\": null\n",
      "    },\n",
      "    {\n",
      "      \"id\": null,\n",
      "      \"score\": 0.515205713273858,\n",
      "      \"filename\": \"Create materials from texture folder.txt\",\n",
      "      \"metadata\": null\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "=== Agent Output (text) ===\n",
      "{\"company_name\":\"\",\"industry\":\"\",\"headquarters_location\":\"\",\"company_size\":\"\",\"website\":\"\",\"description\":\"Извините, у меня нет информации по созданию diagonal panel в SmartWOP.\",\"founded_year\":0.0}\n",
      "\n",
      "=== Agent Output (parsed) ===\n",
      "{\n",
      "  \"company_name\": \"\",\n",
      "  \"industry\": \"\",\n",
      "  \"headquarters_location\": \"\",\n",
      "  \"company_size\": \"\",\n",
      "  \"website\": \"\",\n",
      "  \"description\": \"Извините, у меня нет информации по созданию diagonal panel в SmartWOP.\",\n",
      "  \"founded_year\": 0.0\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Artem\\AppData\\Local\\Temp\\ipykernel_17612\\1996266641.py:99: PydanticDeprecatedSince20: The `json` method is deprecated; use `model_dump_json` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  \"output_text\": result.final_output.json(),           # <- корректно\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import asyncio\n",
    "from openai import AsyncOpenAI\n",
    "from pydantic import BaseModel\n",
    "from types import SimpleNamespace\n",
    "from agents import Agent, ModelSettings, Runner, RunConfig\n",
    "from openai.types.shared.reasoning import Reasoning\n",
    "\n",
    "VECTOR_STORE_ID = \"vs_68e4fc9fa5948191a7b26eace8b8c7d9\"\n",
    "\n",
    "client = AsyncOpenAI()\n",
    "ctx = SimpleNamespace(guardrail_llm=client)\n",
    "\n",
    "class SummarizeAndDisplaySchema(BaseModel):\n",
    "    company_name: str\n",
    "    industry: str\n",
    "    headquarters_location: str\n",
    "    company_size: str\n",
    "    website: str\n",
    "    description: str\n",
    "    founded_year: float\n",
    "\n",
    "summarize_and_display = Agent(\n",
    "    name=\"Summarize and display\",\n",
    "    instructions=\"\"\"You are a helpful assistant for a CAD app (SmartWOP).  \n",
    "Answer ONLY using the provided context.  \n",
    "Prefer step-by-step, concise instructions. Keep tool/command names verbatim.\n",
    "Rules: \n",
    "- Answer ONLY using the information from the context above. \n",
    "- Do NOT mention block numbers or the word 'context'.\n",
    "- Do NOT show your reasoning, inner thoughts, or explanations of how you found the answer.\n",
    "- Provide only the final clear instructions or factual answer. \n",
    "- Answer in the same language as the user question.\"\"\",\n",
    "    model=\"gpt-5\",\n",
    "    output_type=SummarizeAndDisplaySchema,\n",
    "    model_settings=ModelSettings(store=True, reasoning=Reasoning(effort=\"minimal\")),\n",
    ")\n",
    "\n",
    "class WorkflowInput(BaseModel):\n",
    "    input_as_text: str\n",
    "\n",
    "async def safe_vector_search(query: str, limit: int = 10):\n",
    "    \"\"\"\n",
    "    Универсальный обёртка: работает и если search() возвращает AsyncPaginator,\n",
    "    и если возвращает объект с .data.\n",
    "    \"\"\"\n",
    "    res = await client.vector_stores.search(\n",
    "        vector_store_id=VECTOR_STORE_ID,\n",
    "        query=query,\n",
    "        max_num_results=limit,\n",
    "    )\n",
    "\n",
    "    items = []\n",
    "    # Вариант 1: новый SDK вернул асинхронный пагинатор\n",
    "    try:\n",
    "        # если это пагинатор — у него нет .data и нужна асинхронная итерация\n",
    "        async for r in res:\n",
    "            items.append(r)\n",
    "    except TypeError:\n",
    "        # Вариант 2: старый/другой объект с полем .data\n",
    "        data = getattr(res, \"data\", [])\n",
    "        for r in data:\n",
    "            items.append(r)\n",
    "\n",
    "    # Нормализуем поля на всякий случай\n",
    "    norm = []\n",
    "    for r in items:\n",
    "        # часто встречаются r.id / r.score / r.filename / r.metadata\n",
    "        norm.append({\n",
    "            \"id\": getattr(r, \"id\", None),\n",
    "            \"score\": getattr(r, \"score\", None),\n",
    "            \"filename\": getattr(r, \"filename\", None),\n",
    "            \"metadata\": getattr(r, \"metadata\", None),\n",
    "        })\n",
    "    return norm\n",
    "\n",
    "async def run_workflow(workflow_input: WorkflowInput):\n",
    "    workflow = workflow_input.model_dump()\n",
    "\n",
    "    conversation_history = [\n",
    "        {\"role\": \"user\", \"content\": [{\"type\": \"input_text\", \"text\": workflow[\"input_as_text\"]}]}\n",
    "    ]\n",
    "\n",
    "    filesearch_result = {\n",
    "        \"results\": await safe_vector_search(workflow[\"input_as_text\"], limit=10)\n",
    "    }\n",
    "\n",
    "    result = await Runner.run(\n",
    "        summarize_and_display,\n",
    "        input=conversation_history,\n",
    "        run_config=RunConfig(trace_metadata={\n",
    "            \"__trace_source__\": \"agent-builder\",\n",
    "            \"workflow_id\": \"wf_68e4fc2fac808190956b9d82518edbbd07ef705c9c34c8a3\",\n",
    "        }),\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"filesearch_result\": filesearch_result,\n",
    "        \"output_text\": result.final_output.json(),           # <- корректно\n",
    "        \"output_parsed\": result.final_output.model_dump(),   # <- корректно\n",
    "    }\n",
    "\n",
    "# ---- демо-запуск ----\n",
    "\n",
    "async def main():\n",
    "    wf_input = WorkflowInput(\n",
    "        input_as_text=\"Как сделать diagonal panel?\"\n",
    "    )\n",
    "    out = await run_workflow(wf_input)\n",
    "\n",
    "    print(\"=== File Search Result ===\")\n",
    "    print(json.dumps(out[\"filesearch_result\"], ensure_ascii=False, indent=2))\n",
    "\n",
    "    print(\"\\n=== Agent Output (text) ===\")\n",
    "    print(out[\"output_text\"])\n",
    "\n",
    "    print(\"\\n=== Agent Output (parsed) ===\")\n",
    "    print(json.dumps(out[\"output_parsed\"], ensure_ascii=False, indent=2))\n",
    "\n",
    "# В Jupyter:\n",
    "# await main()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # обычный .py\n",
    "    await main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
